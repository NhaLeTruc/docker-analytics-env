services:

  spark-thrift:
    image: bitnami/spark:3.5.6-debian-12-r0
    container_name: spark-thrift
    depends_on:
      spark-master:
        condition: service_healthy
    command: [
      "/opt/bitnami/spark/sbin/start-thriftserver.sh",
      "--conf", "spark.cores.max=2",
      "--conf", "spark.master=spark://spark-master:7077"
    ]
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    healthcheck:
      test: ["CMD-SHELL", "bash -c '</dev/tcp/localhost/10000'"]
      interval: 15s
      timeout: 15s
      retries: 5
      start_period: 30s
    ports:
      - "10000:10000"
    volumes:
      # - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./dqops_userhome/.data/check_results:/data/check_results
    networks:
      - lakehouse_network

  # Free 14 days trial key ended  
  dqops:
    image: dqops/dqo
    container_name: data-quality-ops
    command: ${DQO_CMD}
    ports:
      - "8889:8888"
    volumes:
      - ./dqops_userhome:/dqo/userhome
    healthcheck:
      test: ["CMD-SHELL", "bash -c '</dev/tcp/localhost/8888'"]
      interval: 15s
      timeout: 15s
      retries: 5
      start_period: 30s
    networks:
      - lakehouse_network

  zeppelin:
    # image: apache/zeppelin:0.12.0
    build:
      context: ./zeppelin
      dockerfile: Dockerfile.zeppelin
    container_name: zeppelin    
    user: "${UID}:${GID}"
    command: ["sh", "-c", "/opt/bitnami/zeppelin/bin/zeppelin-daemon.sh start"]
    ports:
      - "8888:8888"
    healthcheck:
      test: ["CMD-SHELL", "bash -c '</dev/tcp/localhost/8888'"]
      interval: 15s
      timeout: 15s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        reservations:
          cpus: '12.0'
          memory: 12G
        limits:
          cpus: '13.0'
          memory: 13G
    volumes:
      - ./spark_apps:/zeppelin/spark
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    entrypoint: >
      /bin/bash -c "
      /opt/bitnami/zeppelin/bin/zeppelin-daemon.sh start \
      tail -f /dev/null
      "
    networks:
      - lakehouse_network

  jupyterlab:
    container_name: jupyterlab
    depends_on:
      spark-master:
        condition: service_healthy
    build: 
      context: ./jupyter
      dockerfile: Dockerfile.jupyterlab
    command: python -m jupyterlab --ip "0.0.0.0" --no-browser --NotebookApp.token='XXXXX-XXXX-XXXX' --NotebookApp.iopub_data_rate_limit=1000000000
    ports:
      - 8888:8888
    volumes:
      - ./jupyter/notebooks:/opt/bitnami/notebooks # persistent storage
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_CONFIG_DIR=/opt/bitnami/notebooks/config
      - JUPYTER_PATH=/opt/bitnami/notebooks/data
      - JUPYTER_RUNTIME_DIR=/opt/bitnami/notebooks/runtime
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - MINIO_END_POINT=minio-lake:9000
    healthcheck:
      test: ["CMD-SHELL", "bash -c '</dev/tcp/localhost/8888'"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - lakehouse_network

  spark-jupyterlab:
    # image: bitnami/spark:3.5.6-debian-12-r0
    container_name: spark-master
    # command: bin/spark-class org.apache.spark.deploy.master.Master
    build: 
      context: ./spark
      dockerfile: Dockerfile
    env_file:
      - spark/.env
      - .env
    healthcheck:
      test: ["CMD-SHELL", "if bash -c '</dev/tcp/localhost/8080' && bash -c '</dev/tcp/localhost/8888'; then exit 0; else exit 1; fi"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
      MINIO_END_POINT: minio-lake:9000
      SPARK_MASTER_HOST: spark-master
      SPARK_HISTORY_OPTS: -Dspark.history.fs.logDirectory=/tmp/spark-events
      JUPYTER_ENABLE_LAB: yes
      JUPYTER_CONFIG_DIR: /opt/bitnami/notebooks/config
      JUPYTER_PATH: /opt/bitnami/notebooks/data
      JUPYTER_RUNTIME_DIR: /opt/bitnami/notebooks/runtime
    ports:
      - "8080:8080"             # Master Web UI
      - "7077:7077"             # Master Port for job submissions
      - "18080:18080"           # Spark History Server
      - "4040-4050:4040-4050"   # Driver UIs (one port per SparkContext)
      - "8888:8888"             # JupyterLab
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark_apps:/opt/bitnami/spark/apps
      - ./spark/notebooks:/opt/bitnami/notebooks
      - spark-logs:/tmp/spark-events
    entrypoint: >
      /bin/bash -c "
      /opt/bitnami/spark/sbin/start-master.sh & \
      /opt/bitnami/spark/sbin/start-history-server.sh & \
      jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --NotebookApp.token='XXXXX-XXXXX-XXXXX' & \
      tail -f /dev/null
      "
    networks:
      - lakehouse_network

  spark-zeppelin:
    # image: bitnami/spark:3.5.6-debian-12-r0
    container_name: spark-master
    build:
      context: ./spark
      dockerfile: Dockerfile.zeppelin
    env_file: .env
    # Healthcheck on 8888 caused container exited
    healthcheck:
      test: ["CMD-SHELL", "if bash -c '</dev/tcp/localhost/8080' && bash -c '</dev/tcp/localhost/18080'; then exit 0; else exit 1; fi"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        reservations:
          cpus: '12.0'
          memory: 12G
        limits:
          cpus: '13.0'
          memory: 13G
    environment:
      - SPARK_MODE=master
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"             # Master Web UI
      - "7077:7077"             # Master Port for job submissions
      - "18080:18080"           # Spark History Server
      - "4040-4050:4040-4050"   # Driver UIs (one port per SparkContext)
      - "8888:8888"             # Zeppelin UI
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark_apps:/opt/bitnami/spark/apps
      - spark-logs:/tmp/spark-events
    entrypoint: >
      /bin/bash -c "
      /opt/bitnami/spark/sbin/start-master.sh & \
      /opt/bitnami/spark/sbin/start-history-server.sh & \
      /opt/bitnami/zeppelin/bin/zeppelin-daemon.sh start & \
      tail -f /dev/null
      "
    networks:
      - lakehouse_network

  spark-livy:
    container_name: spark-livy
    build: 
      context: ./livy
      dockerfile: Dockerfile
    command: [ "sh", "-c", "/opt/bitnami/livy/bin/livy-server" ]
    volumes:
      - type: bind
        source: ./livy/conf/
        target: /opt/bitnami/livy/conf/
    ports:
      - '8998:8998'
    networks:
      - lakehouse_network
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2

networks:
  lakehouse_network:
    driver: bridge

volumes:
  zeppelin-logs: