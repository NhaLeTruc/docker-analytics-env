# spark configs
spark.master                            spark://spark-master:7077
spark.jars.packages                     org.apache.hadoop:hadoop-aws:3.3.5,io.delta:delta-core_2.12:2.4.0,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.3,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.78.0
spark.jars.repositories                 https://mvnrepository.com/artifact,https://repo1.maven.org/maven2,https://repository.apache.org/content/groups/public/,https://oss.sonatype.org/content/repositories/snapshots,https://maven-central.storage-download.googleapis.com/maven2/,https://mmlspark.azureedge.net/maven
# minio
spark.hadoop.fs.s3a.endpoint            http://minio-lake:9000
spark.hadoop.fs.s3a.path.style.access   true
spark.hadoop.fs.s3a.impl                org.apache.hadoop.fs.s3a.S3AFileSystem
fs.s3a.connection.ssl.enabled           false

# These credential should be restrieved through ENV
# spark.hadoop.fs.s3a.access.key          minioadmin
# spark.hadoop.fs.s3a.secret.key          minioadmin
# spark.hadoop.fs.s3a.endpoint            minio_endpoint

# spark logs
spark.eventLog.enabled                 true
spark.eventLog.dir                     /tmp/spark-events
spark.history.fs.logDirectory          /tmp/spark-events

# Iceberg and Nessie
spark.sql.extensions                   org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions
# Configure Nessie catalog
spark.sql.catalog.data                 org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.data.catalog-impl    org.apache.iceberg.nessie.NessieCatalog
spark.sql.catalog.data.uri             http://nessie:19120/api/v1
spark.sql.catalog.data.ref             main
spark.sql.defaultCatalog               data
spark.sql.catalog.data.authentication.type  NONE
# Set Minio as the S3 endpoint for Iceberg storage
spark.sql.catalog.data.warehouse       s3a://myminio/datalakehouse
spark.sql.catalog.data.s3.endpoint	   http://minio-lake:9000
spark.sql.catalog.data.io-impl		   org.apache.iceberg.aws.s3.S3FileIO

# spark.sql.catalog.data.authentication.type  BEARER
# spark.sql.catalog.data.authentication.token XXXXX-XXXXX-XXXXX

# These are for different types of catalog: HIVE
# spark.sql.catalogImplementation        in-memory
# spark.sql.catalogImplementation        hive

# ======================================================================================
# Performance Tuning Configurations
# ======================================================================================
#
spark.sql.execution.pyarrow.enabled    true
# These settings are configured to maximize resource utilization for faster processing.
#
# -- Resource Allocation ---------------------------------------------------------------
# Use dynamic allocation to let Spark scale executors based on workload.
spark.dynamicAllocation.enabled                 true
spark.dynamicAllocation.shuffleTracking.enabled true
spark.dynamicAllocation.minExecutors            1
spark.dynamicAllocation.maxExecutors            10
spark.dynamicAllocation.initialExecutors        2

# -- General Execution -----------------------------------------------------------------
spark.cores.max                     12

# -- Memory Settings -------------------------------------------------------------------
spark.driver.memory                 12g
spark.executor.memory               12g
spark.executor.memoryOverhead       1g


