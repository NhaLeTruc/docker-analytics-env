# spark master
spark.master                       spark://spark-master:7077
# minio
spark.hadoop.fs.s3a.endpoint        http://minio:9000
spark.hadoop.fs.s3a.path.style.access true
spark.hadoop.fs.s3a.impl            org.apache.hadoop.fs.s3a.S3AFileSystem

spark.hadoop.fs.s3a.access.key minioadmin
spark.hadoop.fs.s3a.secret.key minioadmin

# ======================================================================================
# Performance Tuning Configurations
# ======================================================================================
#
# These settings are configured to maximize resource utilization for faster processing.
#
# -- Resource Allocation ---------------------------------------------------------------
# Use dynamic allocation to let Spark scale executors based on workload.
spark.dynamicAllocation.enabled         true
spark.dynamicAllocation.shuffleTracking.enabled true
spark.dynamicAllocation.minExecutors    1
spark.dynamicAllocation.maxExecutors    10
spark.dynamicAllocation.initialExecutors 2

# -- General Execution -----------------------------------------------------------------
# This tells Spark to use all available cores on the worker nodes for tasks.
spark.cores.max                     12

# -- Memory Settings -------------------------------------------------------------------
# With 3 executors, this will consume ~15GB at peak (3 * (4g + 1g))
spark.driver.memory                 8g
spark.executor.memory               8g
spark.executor.memoryOverhead       1g


