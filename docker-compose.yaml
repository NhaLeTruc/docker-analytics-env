######################################################################################
### Iceberg - MinIO - Nessie Catalog - Spark - JupyterLab - SuperSet - DqOps Setup ###
######################################################################################
services:
  ###########
  ## MinIO ##
  ###########
  minio-lake:
    image: bitnami/minio:2025.6.13-debian-12-r0
    container_name: minio-lake
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # Web console
    volumes:
      - minio-data:/opt/bitnami/minio/data
      - ./data_seeder/dummy:/opt/bitnami/minio/dummy
    entrypoint: >
      /bin/sh -c "
      minio server /bitnami/minio/data --console-address ':9001'
      tail -f /dev/null"
    networks:
      - lakehouse_network

  ########################
  ## Spark and Notebook ##
  ########################
  spark-master:
    container_name: spark-master
    build:
      context: ./spark
      dockerfile: Dockerfile.jupyterlab
    env_file: .env
    environment:
      - SPARK_MODE=master
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events
      - JUPYTER_ENABLE_LAB=yes
    ports:
      - "8080:8080"             # Master Web UI
      - "7077:7077"             # Master Port for job submissions
      - "18080:18080"           # Spark History Server
      - "4040-4050:4040-4050"   # Driver UIs (one port per SparkContext)
      - "8888:8888"             # JupyterLab
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark/jupyter/notebooks:/opt/bitnami/jupyter/notebooks
    entrypoint: >
      /bin/bash -c "
      /opt/bitnami/spark/sbin/start-master.sh & \
      /opt/bitnami/spark/sbin/start-history-server.sh & \
      tail -f /dev/null
      "
    networks:
      - lakehouse_network

  spark-worker-1:
    image: bitnami/spark:3.5.6-debian-12-r0
    container_name: spark-worker-1
    env_file: .env
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - lakehouse_network

  spark-worker-2:
    image: bitnami/spark:3.5.6-debian-12-r0
    container_name: spark-worker-2
    env_file: .env
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - lakehouse_network

  #################
  ## Postgres DB ##
  #################
  postgres:
    image: postgres:16
    volumes:
      - meta_data:/var/lib/postgresql/data/
    networks:
      - lakehouse_network

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin4
    ports:
      - "5050:80"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - pgadata:/var/lib/pgadmin
    networks:
      - lakehouse_network

  ####################
  ## Nessie Catalog ##
  ####################
  nessie:
    image: ghcr.io/projectnessie/nessie:latest
    container_name: nessie-catalog
    ports:
      - "19120:19120"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - QUARKUS_PROFILE=dev
      - QUARKUS_HTTP_PORT=19120
      - QUARKUS_LOG_CONSOLE_FORMAT=%d{yyyy-MM-dd HH:mm:ss} %-5p [%c{1.}] (%t) %s%e%n
      - QUARKUS_LOG_LEVEL=INFO
    networks:
      - lakehouse_network

  ##############
  ## Superset ##
  ##############
  superset:
    container_name: superset
    build:
      context: ./superset
      dockerfile: Dockerfile
    volumes:
      - superset_data:/app/superset_home
    ports:
      - "8088:8088"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - lakehouse_network

networks:
  lakehouse_network:
    driver: bridge

volumes:
  minio-data:
  spark-logs:
  pgadata:
  superset_data:
  meta_data:

